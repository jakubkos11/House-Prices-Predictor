{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, FunctionTransformer, StandardScaler, PolynomialFeatures\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score, make_scorer\n\nclass Config:\n    \"\"\"A class that stores all configurations and constants.\"\"\"\n    # Mapping ordinal features\n    ORDINAL_FEATURE_MAP = {\n        'ExterQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'ExterCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'BsmtQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'BsmtCond': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'BsmtExposure': ['None', 'No', 'Mn', 'Av', 'Gd'],\n        'BsmtFinType1': ['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n        'BsmtFinType2': ['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n        'HeatingQC': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'KitchenQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'GarageFinish': ['None', 'Unf', 'RFn', 'Fin'],\n        'GarageQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'GarageCond': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'PavedDrive': ['N', 'P', 'Y'],\n        'Fence': ['None', 'MnWw', 'GdWo', 'MnPrv', 'GdPrv'],\n        'OverallQual': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n        'OverallCond': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n        'Functional': ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],\n        'FireplaceQu': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n        'PoolQC': ['None', 'Fa', 'TA', 'Gd', 'Ex'],\n        'LotShape': ['IR3', 'IR2', 'IR1', 'Reg'],\n        'LandContour': ['Low', 'HLS', 'Bnk', 'Lvl'],\n        'LandSlope': ['Sev', 'Mod', 'Gtl']\n    }\n\n    # Lists of features grouped by different types\n    NOMINAL_FEATURES = [\n        'MSSubClass', 'MSZoning', 'Alley', 'LotConfig', 'Neighborhood',\n        'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle',\n        'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation',\n        'Heating', 'Electrical', 'GarageType', 'MiscFeature', 'SaleType',\n        'SaleCondition'\n    ]\n\n    SKEWED_FEATURES = [\n        'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF', \n        'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', \n        'WoodDeckSF', 'OpenPorchSF', 'AgeHouse', 'AgeSinceRemod', 'TotalSF'\n    ]\n    \n    NUMERIC_FEATURES = [\n        'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFullBath', \n        'FullBath', 'HalfBath', 'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', \n        'GarageYrBlt', 'GarageCars', 'YrSold', 'IsRemodeled', 'TotalBaths', 'OverallScore'\n    ]\n\nclass HousingPricePredictor:\n    \"\"\"Class used for training a model and predicting house prices.\"\"\"\n    def __init__(self, config):\n        self.config = config\n        self.preprocessor = None\n        self.model = LassoCV(cv = 10, max_iter = 20000, random_state = 1, n_jobs = -1)\n\n    @staticmethod\n    def _print_evaluation_metrics(y_true, y_pred, dataset_name):\n        \"\"\"Print evaluation metrics for given dataset.\"\"\"\n        print(f\"\\n=== Metryki dla zbioru {dataset_name} ===\")\n        print(f\"R²: {r2_score(np.expm1(y_true), np.expm1(y_pred)):.4f}\")\n        print(f\"RMSLE: {mean_squared_log_error(np.expm1(y_true), np.expm1(y_pred), squared=False):.4f}\")\n        print(f\"MAE: {mean_absolute_error(np.expm1(y_true), np.expm1(y_pred)):.2f}\")\n        \n    def _clean_data(self, data):\n        \"\"\"Handles missing values correctly based on their meaning.\"\"\"\n        df = data.copy()\n        # Define strategies of handling with missing data\n        cols_na_as_none = [\n            'Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n            'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageFinish',\n            'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature', 'MasVnrType'\n        ]\n        cols_na_as_zero = [\n            'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n            'BsmtHalfBath', 'GarageArea', 'GarageCars', 'MasVnrArea'\n        ]\n        # Columns to fill with the most frequent value per category\n        cols_na_as_mode = [\n            'MSZoning', 'Functional', 'Electrical',\n            'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType'\n        ]\n        # Fill missed values in specified columns\n        for col in cols_na_as_none:\n            df[col] = df[col].fillna('None')\n    \n        for col in cols_na_as_zero:\n            df[col] = df[col].fillna(0)\n\n        for col in cols_na_as_mode:\n            df[col] = df[col].fillna(df[col].mode()[0])\n\n        # Fill with median from neighborhood, then with global median if there are empty values left\n        df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(\n            lambda x: x.fillna(x.median()))\n        \n        if df['LotFrontage'].isnull().any():\n            df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].median())\n\n        # If no info about GarageYrBlt then fill with house year built\n        df['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['GarageYrBlt'].median())\n        \n        # Switch formats of some variables for convinience\n        df['MSSubClass'] = df['MSSubClass'].astype(str)\n        df['CentralAir'] = df['CentralAir'].map({'Y': 1, 'N': 0})\n        \n        return df\n\n    def _apply_feature_engineering(self, data):\n        \"\"\"Add custom engineering features to improve predictive power of the model.\"\"\"\n        df = data.copy()\n        df['AgeHouse'] = (df['YrSold'] - df['YearBuilt']).clip(lower=0)\n        df['AgeSinceRemod'] = (df['YrSold'] - df['YearRemodAdd']).clip(lower=0)\n        df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n        df['IsRemodeled'] = (df['YearRemodAdd'] > df['YearBuilt']).astype(int)\n        df['TotalBaths'] = df['FullBath'] + 0.5 * df['HalfBath'] + df['BsmtFullBath'] + 0.5 * df['BsmtHalfBath']\n        df['OverallScore'] = df['OverallQual'] * df['OverallCond']\n        df = df.drop(['Utilities', 'Street', 'MoSold'], axis = 1, errors='ignore')\n        return df\n\n    def _filter_outliers(self, X, y):\n        \"\"\"Detect and remove outliers from training set.\"\"\"\n        # Select only skewed features with high feature importance for selection\n        outlier_detection_features = ['GrLivArea', 'OverallQual', 'TotalSF', \n                                      'YearBuilt', 'TotalBaths', 'GarageArea']\n        \n        clf = IsolationForest(n_estimators = 100, contamination = 0.005, random_state = 1)\n        outlier_preds = clf.fit_predict(X[outlier_detection_features].fillna(0).values) # Return 1 for normal and -1 for outliers\n        \n        non_outlier_indices = np.where(outlier_preds == 1)[0]\n        \n        return X.iloc[non_outlier_indices], y.iloc[non_outlier_indices]\n\n    def _build_preprocessor(self):\n        \"\"\"Build pipeline for data preprocessing.\"\"\"\n        # Transform ordinal map into keys and values\n        ordinal_features = list(self.config.ORDINAL_FEATURE_MAP.keys())\n        ordinal_categories = list(self.config.ORDINAL_FEATURE_MAP.values())\n            \n        # Pipeline for numerical features, fill missing values with median\n        numeric_transformer = Pipeline(steps = [\n            ('imputer', SimpleImputer(strategy = 'median')),\n            ('scaler', StandardScaler())\n        ])\n        \n        # Pipeline for skewed numerical features\n        skewed_transformer = Pipeline(steps = [\n            ('imputer', SimpleImputer(strategy = 'median')),\n            ('log', FunctionTransformer(np.log1p, validate = False, feature_names_out = 'one-to-one')),\n            ('scaler', StandardScaler())\n        ])\n\n        # Pipeline for ordinal features\n        ordinal_transformer = Pipeline(steps = [\n            ('imputer', SimpleImputer(strategy = 'most_frequent')),\n            ('encoder', OrdinalEncoder(\n                categories = ordinal_categories,\n                handle_unknown = 'use_encoded_value',\n                unknown_value = -1\n            )),\n            ('scaler', StandardScaler())\n        ])\n\n        # Pipeline for nominal features\n        nominal_transformer = Pipeline(steps = [\n            ('imputer', SimpleImputer(strategy = 'most_frequent')),\n            ('onehot', OneHotEncoder(handle_unknown = 'ignore', sparse_output = False))\n        ])\n        \n        # Combine all transformers in single ColumnTransformer\n        preprocessor = ColumnTransformer(transformers = [\n            ('num', numeric_transformer, self.config.NUMERIC_FEATURES),\n            ('skewed', skewed_transformer, self.config.SKEWED_FEATURES),\n            ('ord', ordinal_transformer, ordinal_features),\n            ('nom', nominal_transformer, self.config.NOMINAL_FEATURES)\n        ], remainder = 'passthrough')\n        return preprocessor\n\n    def train(self, X, y):\n        \"\"\"Train final model.\"\"\"\n        # Split data into train and validation set\n        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 1)\n\n        self.preprocessor = self._build_preprocessor()\n        \n        pipeline = Pipeline(steps=[\n            ('preprocessor', self.preprocessor),\n            ('regressor', self.model)\n        ])\n        pipeline.fit(X_train, y_train)\n    \n        # Evaluation on train and validation sets\n        y_train_pred = pipeline.predict(X_train)\n        y_val_pred = pipeline.predict(X_val)\n    \n        # Show performance metrics\n        best_alpha = pipeline.named_steps['regressor'].alpha_\n        print(f\"\\nBest alpha found by LassoCV: {best_alpha:.4f}\")\n        self._print_evaluation_metrics(y_train, y_train_pred, \"Training\")\n        self._print_evaluation_metrics(y_val, y_val_pred, \"Validation\")\n\n        # Train final model\n        pipeline.fit(X, y)\n        self.model = pipeline\n        \n    def predict(self, X_test):\n        \"\"\"Generate predictions on test data.\"\"\"\n        return self.model.predict(X_test)\n\n    def run(self):\n        \"\"\"Runs whole pipeline.\"\"\"\n        # Load both datasets\n        train_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n        test_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n        test_ids = test_df['Id']\n    \n        # Separate features and target\n        X = train_df.drop(['SalePrice', 'Id'], axis = 1, errors = 'ignore')\n        y = np.log1p(train_df['SalePrice'])\n        X_test = test_df.drop(['Id'], axis = 1, errors = 'ignore')\n            \n        # Clean the data\n        X = self._clean_data(X)\n        X_test = self._clean_data(X_test)\n        \n        # Add new features to the model\n        X = self._apply_feature_engineering(X)\n        X_test = self._apply_feature_engineering(X_test)\n    \n        # Remove houses with extremaly skewed features\n        X, y = self._filter_outliers(X, y)\n    \n        # Reset indices after removing unwanted features\n        X = X.reset_index(drop = True)\n        y = y.reset_index(drop = True)\n        X_test = X_test.reset_index(drop = True)\n    \n        # Train model\n        self.train(X, y)\n        \n        # Predictions\n        final_predictions = self.predict(X_test)\n        \n        # Generate submission file\n        submission = pd.DataFrame({'Id': test_ids, 'SalePrice': np.expm1(final_predictions)})        \n        submission.to_csv('submission.csv', index = False)\n\n# Main function\nif __name__ == '__main__':\n    config = Config()\n    predictor = HousingPricePredictor(config)\n    predictor.run()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T14:50:15.427961Z","iopub.execute_input":"2025-09-21T14:50:15.428304Z","iopub.status.idle":"2025-09-21T14:50:16.875232Z","shell.execute_reply.started":"2025-09-21T14:50:15.428281Z","shell.execute_reply":"2025-09-21T14:50:16.874281Z"}},"outputs":[{"name":"stdout","text":"\nBest alpha found by LassoCV: 0.0043\n\n=== Metryki dla zbioru Training ===\nR²: 0.9096\nRMSLE: 0.1153\nMAE: 14996.82\n\n=== Metryki dla zbioru Validation ===\nR²: 0.9055\nRMSLE: 0.1298\nMAE: 15171.83\n","output_type":"stream"}],"execution_count":20}]}